spring:
  application:
    name: 'spring-cloud-stream-kafka-avro-app'
  main:
    allow-bean-definition-overriding: true
  datasource:
    url: 'jdbc:h2:mem:db;DB_CLOSE_DELAY=-1'
    username: 'sa'
    password: 'sa'
  h2:
    console:
      enabled: true
      path: '/h2-console'
  cloud:
    stream:
      default:
        producer:
          use-native-encoding: true
        consumer:
          use-native-encoding: true
      bindings:
        input:
          binder: kafka
          destination: queueing.example.customer.created
          content-type: application/*+avro
          group: ${spring.application.name}
        output:
          binder: kafka
          destination: queueing.example.customer.created
          content-type: application/*+avro
      kafka:
        binder:
          brokers: 'localhost:29092'
          auto-create-topics: false
          auto-add-partitions: false
          health-timeout: 30
          producer-properties:
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
            value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
            schema.registry.url: http://localhost:8081
          consumer-properties:
            key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
            value.deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
            schema.registry.url: http://localhost:8081
            specific.avro.reader: true
logging:
  level:
    org.springframework: INFO
    net.elau.example.springcloudstreamkafkaavro: DEBUG
